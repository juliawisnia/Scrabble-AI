Problem 2
Array: [1, 7, 3, 12, 5, 2, 4, 6, 8, 10, 11, 9]
I solved this problem by starting off with a blank array,
and always taking the pivot to be the smallest element I could.
However, because the median ensures that the pivot will never
be the true smallest elememt, I always assumed that as more
and more arrays were broken up, the first and middle array
elements were the two smallest remaining elements. So, 
array[0] = 1, and array[5] = 2, because those are the first
elements being compared by the median to be the pivot.  Because
they are the smallest, each time QuickSort runs, it will have 
to move all other n - 2 elements to the right side of the "wall,"
ensuring that the maximum swaps take place.  The wall was moved
past these two elements, and I did the same process over with
the other n - 2 elements, the first being the smallest and middle
second smallest.

Problem 4(c)
My function mergeSort is really just a wrapper for my helper 
functions, multMergeSort, merge, and selectionSort, so I will analyze
those first.

selectionSort:
This is the basic implementation of selectionSort, thus the runtime
for this algorithm is n^2, where n is the number of elements being
sorted.  However, this is only called when n < k, so it does not
overtake the good runtime of multMergeSort.

merge:
My merge function takes in indicies representing sorted partitions
of the overall array, and then compares these arrays, up to k, and
repeatedly finds the min, pushing it into a temp vector.  In it's
worst case, it will take n time, because it will be merging all of
the partitions of the array.

multMergeSort:
This is repeatedly calling itself until each partition of the array
is less than k.  It also calls the other two functions from here.
The first for loop, which partitions the elements, takes k time,
because it is pushing back into the index array k times on a maximum
input of n.  Each time that merge is called, it is getting k times
smaller, but still operating on the maximum input of n.  Because
it calls merge k times its overall runtime is:

O(n*k*log (base k) n)

We know that selection sort will be O((k-1)^2) each time, so we can
safely ignore that in our analysis because it is overatken by the
runtime of merge and multMergeSort.

So, that means when k = n, it becomes an n^2 algorithm, and in addition,
it would not have any order beyond the individual sorted elements when
it calls merge, so in the worst case there is not a chance for it to
quit early, meaning that it would closely resemble BubbleSort in its
worst case, and other n^2 algorithms such as SelectionSort.
